{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "from ast import literal_eval\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv files which contain head bounding box & key point coordinates\n",
    "Bounding boxes and key points were generated with a third pary dog detector: https://github.com/kairess/dog_face_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"../csv_files/preprocessing_img_data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70403 entries, 0 to 70402\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   index                    70403 non-null  int64  \n",
      " 1   img_name                 70403 non-null  object \n",
      " 2   num_pixels_initial_crop  70403 non-null  int64  \n",
      " 3   bb                       70403 non-null  bool   \n",
      " 4   lm                       70403 non-null  bool   \n",
      " 5   bb_x1                    44223 non-null  float64\n",
      " 6   bb_x2                    44223 non-null  float64\n",
      " 7   bb_y1                    44223 non-null  float64\n",
      " 8   bb_y2                    44223 non-null  float64\n",
      " 9   lm_00                    44223 non-null  object \n",
      " 10  lm_01                    44223 non-null  object \n",
      " 11  lm_02                    44223 non-null  object \n",
      " 12  lm_03                    44223 non-null  object \n",
      " 13  lm_04                    44223 non-null  object \n",
      " 14  lm_05                    44223 non-null  object \n",
      "dtypes: bool(2), float64(4), int64(2), object(7)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 images were lost during preprocessing.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{70428 - len(df_all)} images were lost during preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bounding box could only be detected for 44223 images.\n"
     ]
    }
   ],
   "source": [
    "print(f\"A bounding box could only be detected for {len(df_all[df_all['bb'] == True])} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out bad images and refine crops\n",
    "\n",
    "### Filter 1:\n",
    "Filter out all images with a resolution lower than 65k pixesls (250x250)\n",
    "\n",
    "### Filter 2:\n",
    "Filter out all images were no bounding box & keypoints are detected.\n",
    "\n",
    "### Filter 3:\n",
    "Filter out all images which show a side view of a dog face. The image shows a side view when the nose is further out than one of the eyes.\n",
    "\n",
    "### Refine crops\n",
    "Adapt bounding box to a square and resize images to 256x256. \n",
    "\n",
    "### Debugging\n",
    "You can uncomment matplotlib calls to see intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 70403\n",
      "Number of images which pass filter 1: 42796\n",
      "Number of images which pass filter 1 & 2: 26040\n",
      "Number of images which pass filter 1,2 & 3: 22930\n",
      "Total number of valid images: 22930\n"
     ]
    }
   ],
   "source": [
    "num_imgs_after_filter_1 = 0\n",
    "num_imgs_after_filter_2 = 0\n",
    "num_imgs_after_filter_3 = 0\n",
    "valid_imgs = 0\n",
    "\n",
    "image_output_dir = Path(\"/scratch/local/ssd/janhr/data/dogs_cropped/all/\")\n",
    "image_input_dir = Path(\"/scratch/local/ssd/janhr/data/tsinghua_dogs_high_res_cropped/all\")\n",
    "image_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    img_name = row[\"img_name\"]\n",
    "    img_path = image_input_dir / img_name\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 1. filter: pixel size\n",
    "    num_pixels = row[\"num_pixels_initial_crop\"]\n",
    "    if num_pixels < 256*256:\n",
    "        continue\n",
    "    num_imgs_after_filter_1 += 1\n",
    "        \n",
    "\n",
    "    # 2. filter check if head and landmarks were detected\n",
    "    if row[\"bb\"] != True or row[\"lm\"] != True:\n",
    "        continue\n",
    "    num_imgs_after_filter_2 += 1\n",
    "\n",
    "    # 3. noise right or left of eye -> side view -> filter out\n",
    "    right_eye = literal_eval(row[\"lm_02\"])\n",
    "    left_eye = literal_eval(row[\"lm_05\"])\n",
    "    noise = literal_eval(row[\"lm_03\"])\n",
    "\n",
    "    if noise[0] > right_eye[0] or noise[0] < left_eye[0]:\n",
    "        continue\n",
    "    num_imgs_after_filter_3 += 1\n",
    "        \n",
    "    \n",
    "    x1 = int(row[\"bb_x1\"])\n",
    "    y1 = int(row[\"bb_y1\"])\n",
    "    x2 = int(row[\"bb_x2\"])\n",
    "    y2 = int(row[\"bb_y2\"])\n",
    "    \n",
    "    img_width = img.shape[1]\n",
    "    img_height = img.shape[0]\n",
    "\n",
    "    x1 = max(0,x1)\n",
    "    x2 = min(img_width,x2)\n",
    "    y1 = max(0,y1)\n",
    "    y2 = min(img_height,y2)\n",
    "    \n",
    "    # 5. Square images\n",
    "    width = x2-x1\n",
    "    height = y2-y1\n",
    "\n",
    "    \n",
    "    # make crop a square\n",
    "    crop = None\n",
    "    if (height > width):\n",
    "        ratio = height/width\n",
    "        border_x1 = int((ratio-1)*width/2)\n",
    "        border_x2 = int((ratio-1)*width/2)\n",
    "        border_x1_copy = 0\n",
    "        border_x2_copy = 0\n",
    "        # make crop wider: change x1 and x2 or copy border\n",
    "        # extend x1 as best as possible\n",
    "        new_x1 = x1 - border_x1\n",
    "        if new_x1 < 0: \n",
    "            # extend x1 as fast as possible and extend border after crop\n",
    "            border_x1_copy = border_x1 - x1\n",
    "#             print(f\"old x1: {x1} new_x1: {new_x1}, broder_x1_copy: {border_x1_copy}\")\n",
    "            new_x1 = 0\n",
    "        x1 = new_x1\n",
    "        \n",
    "        new_x2 = x2 + border_x2\n",
    "        if new_x2 > img_width: \n",
    "            # extend x1 as fast as possible and extend border after crop\n",
    "            border_x2_copy = new_x2 - img_width\n",
    "#             print(f\"old x2: {x2} new_x2: {new_x2}, broder_x2_copy: {border_x2_copy}\")\n",
    "            new_x2 = img_width\n",
    "        x2 = new_x2\n",
    "             \n",
    "        crop = img[y1:y2, x1:x2]\n",
    "#         print(f\"border_x1_copy: {border_x1_copy}, border_x2_copy: {border_x2_copy}\")\n",
    "        crop = cv2.copyMakeBorder(crop,0,0,border_x1_copy,border_x2_copy,cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    elif(width > height):\n",
    "        ratio = width/height\n",
    "        border_y1 = int((ratio-1)*height/2)\n",
    "        border_y2 = int((ratio-1)*height/2)\n",
    "        border_y1_copy = 0\n",
    "        border_y2_copy = 0\n",
    "        # make crop wider: change x1 and x2 or copy border\n",
    "        # extend x1 as best as possible\n",
    "        new_y1 = y1 - border_y1\n",
    "        if new_y1 < 0: \n",
    "            # extend x1 as fast as possible and extend border after crop\n",
    "            border_y1_copy = border_y1 - y1\n",
    "#             print(f\"old y1: {y1} new_y1: {new_y1}, broder_y1_copy: {border_y1_copy}\")\n",
    "            new_y1 = 0\n",
    "        y1 = new_y1\n",
    "        \n",
    "        new_y2 = y2 + border_y2\n",
    "        if new_y2 > img_height: \n",
    "            # extend x1 as fast as possible and extend border after crop\n",
    "            border_y2_copy = new_y2 - img_height\n",
    "#             print(f\"old y2: {y2} new_y2: {new_y2}, broder_y2_copy: {border_y2_copy}\")\n",
    "            new_y2 = img_height\n",
    "        y2 = new_y2\n",
    "\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "#         print(f\"border_y1_copy: {border_y1_copy}, border_y2_copy: {border_y2_copy}\")\n",
    "        crop = cv2.copyMakeBorder(crop,border_y1_copy,border_y2_copy,0,0,cv2.BORDER_REPLICATE)\n",
    "    else:\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "    \n",
    "    \n",
    "# ONLY FOR DEBUG\n",
    "#     fig = plt.figure(figsize=(16,16))\n",
    "#     x1 = int(row[\"bb_x1\"])\n",
    "#     y1 = int(row[\"bb_y1\"])\n",
    "#     x2 = int(row[\"bb_x2\"])\n",
    "#     y2 = int(row[\"bb_y2\"])\n",
    "#     img_org = img.copy()\n",
    "#     cv2.rectangle(img_org, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=(255,0,0), lineType=cv2.LINE_AA)\n",
    "\n",
    "#     shape = np.array([literal_eval(row[\"lm_00\"]),literal_eval(row[\"lm_01\"]),literal_eval(row[\"lm_02\"]),literal_eval(row[\"lm_03\"]),literal_eval(row[\"lm_04\"]), literal_eval(row[\"lm_05\"])])\n",
    "#     for i, p in enumerate(shape):\n",
    "#         cv2.circle(img_org, center=tuple(p), radius=3, color=(0,0,255), thickness=-1, lineType=cv2.LINE_AA)\n",
    "#         cv2.putText(img_org, str(i), tuple(p), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "#     ax1 = fig.add_subplot(221)\n",
    "#     ax1.set_title(\"Original image with bounding box + key points\")\n",
    "#     ax1.xaxis.tick_top()\n",
    "#     ax1.imshow(img_org)\n",
    "    \n",
    "#     ax1 = fig.add_subplot(222)\n",
    "#     ax1.set_title(\"Final cropped img\")\n",
    "#     ax1.xaxis.tick_top()\n",
    "#     ax1.imshow(crop)\n",
    "#     break\n",
    "\n",
    "    # resize and save image\n",
    "    resized_img = cv2.resize(crop, (256,256))\n",
    "    img_out = cv2.cvtColor(resized_img, cv2.COLOR_RGB2BGR)\n",
    "    img_output_path = str(image_output_dir / img_name)\n",
    "    cv2.imwrite(img_output_path, img_out)\n",
    "\n",
    "    # bring image to same size\n",
    "    valid_imgs += 1\n",
    "    print(f\"{index}/{len(df_all)}\", end=\"\\r\")\n",
    "    \n",
    "total_num_imgs = len(df_all)\n",
    "\n",
    "print(f\"Total number of images: {total_num_imgs}\")\n",
    "print(f\"Number of images which pass filter 1: {num_imgs_after_filter_1}\")\n",
    "print(f\"Number of images which pass filter 1 & 2: {num_imgs_after_filter_2}\")\n",
    "print(f\"Number of images which pass filter 1,2 & 3: {num_imgs_after_filter_3}\")\n",
    "print(f\"Total number of valid images: {valid_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
